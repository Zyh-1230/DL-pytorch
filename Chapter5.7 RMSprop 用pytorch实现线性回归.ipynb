{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "042960e3-a3bb-4258-b330-a745fc2d73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5764c0e2-ee86-4b06-8f11-1b939242a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.Tensor([[1.0], [2.0], [3.0]])\n",
    "y_data = torch.Tensor([[2.0], [4.0], [6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735a5b8c-084c-41e9-9848-34e96e79edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造模型\n",
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None) 实现全连接层\n",
    "        # in_features: 输入特征的数量(输入张量的最后一维大小) out_features:输出特征的数量(输出张量的最后一维大小)\n",
    "        # bias:是否添加可学习的偏置项\n",
    "        self.linear = torch.nn.Linear(1, 1) # 输入维度为1 输出维度为1 \n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x) # 对象+() 代表可调用对象\n",
    "        return y_pred\n",
    "\n",
    "model = LinearModel() # model is callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e3f9ef2-daa2-4c61-b771-6186acec80a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# 构造损失函数及优化器\n",
    "# class torch.nn.MSELoss(size_average=True, reduce=True)\n",
    "# size_average是否求所有样本的损失均值 reduce是否为降维处理\n",
    "# criterion(y_head, y)\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "# class torch.optim.SGD(params, lr=<object object>, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "# SGD随机梯度下降\n",
    "# params权重--在model中没有定义相应的权重 只有linear这一个成员 model.parameters()会检查model中所有成员 将相应的权重加到最后的训练结果上\n",
    "# lr--learning rate\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ec372fc-d0c2-435f-a64a-90471ca20d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.96299934387207\n",
      "1 15.803049087524414\n",
      "2 3.424713611602783\n",
      "3 1.9571031332015991\n",
      "4 1.710398554801941\n",
      "5 1.5640592575073242\n",
      "6 1.4353892803192139\n",
      "7 1.3173744678497314\n",
      "8 1.2087851762771606\n",
      "9 1.1088422536849976\n",
      "10 1.0168688297271729\n",
      "11 0.9322423338890076\n",
      "12 0.854390561580658\n",
      "13 0.7827854752540588\n",
      "14 0.7169396877288818\n",
      "15 0.6564052104949951\n",
      "16 0.6007683277130127\n",
      "17 0.5496461987495422\n",
      "18 0.5026870965957642\n",
      "19 0.4595640003681183\n",
      "20 0.41997599601745605\n",
      "21 0.38364630937576294\n",
      "22 0.35031741857528687\n",
      "23 0.3197525441646576\n",
      "24 0.2917327880859375\n",
      "25 0.2660553455352783\n",
      "26 0.24253417551517487\n",
      "27 0.2209957391023636\n",
      "28 0.20128163695335388\n",
      "29 0.1832442730665207\n",
      "30 0.1667480170726776\n",
      "31 0.15166756510734558\n",
      "32 0.13788755238056183\n",
      "33 0.12530110776424408\n",
      "34 0.11381001770496368\n",
      "35 0.10332390666007996\n",
      "36 0.0937589704990387\n",
      "37 0.08503852039575577\n",
      "38 0.07709138095378876\n",
      "39 0.06985292583703995\n",
      "40 0.06326271593570709\n",
      "41 0.05726558715105057\n",
      "42 0.051811009645462036\n",
      "43 0.04685232788324356\n",
      "44 0.04234665259718895\n",
      "45 0.038254640996456146\n",
      "46 0.034540072083473206\n",
      "47 0.031170137226581573\n",
      "48 0.028114160522818565\n",
      "49 0.025344522669911385\n",
      "50 0.022835683077573776\n",
      "51 0.02056414633989334\n",
      "52 0.018508607521653175\n",
      "53 0.016649562865495682\n",
      "54 0.01496911235153675\n",
      "55 0.013450912199914455\n",
      "56 0.012080078944563866\n",
      "57 0.010842865332961082\n",
      "58 0.009727032855153084\n",
      "59 0.008721070364117622\n",
      "60 0.007814832031726837\n",
      "61 0.006998718716204166\n",
      "62 0.006264288444072008\n",
      "63 0.00560374092310667\n",
      "64 0.0050099617801606655\n",
      "65 0.004476525355130434\n",
      "66 0.0039975084364414215\n",
      "67 0.00356770446524024\n",
      "68 0.003182206768542528\n",
      "69 0.0028367203194648027\n",
      "70 0.0025272048078477383\n",
      "71 0.0022501375060528517\n",
      "72 0.002002210356295109\n",
      "73 0.001780554885044694\n",
      "74 0.0015824598958715796\n",
      "75 0.0014055410865694284\n",
      "76 0.001247658976353705\n",
      "77 0.0011067995801568031\n",
      "78 0.0009812430944293737\n",
      "79 0.0008693787967786193\n",
      "80 0.0007697904948145151\n",
      "81 0.0006811712519265711\n",
      "82 0.0006023906753398478\n",
      "83 0.0005323548684827983\n",
      "84 0.00047018867917358875\n",
      "85 0.00041499361395835876\n",
      "86 0.0003660405345726758\n",
      "87 0.00032266794005408883\n",
      "88 0.0002842378453351557\n",
      "89 0.0002502088900655508\n",
      "90 0.0002201228344347328\n",
      "91 0.00019352244271431118\n",
      "92 0.000170018058270216\n",
      "93 0.00014927276060916483\n",
      "94 0.000130965156131424\n",
      "95 0.00011482508125482127\n",
      "96 0.00010061103239422664\n",
      "97 8.80902080098167e-05\n",
      "98 7.707372424192727e-05\n",
      "99 6.739058153470978e-05\n"
     ]
    }
   ],
   "source": [
    "# Training Cycle\n",
    "for epoch in range(100):\n",
    "    # 前馈\n",
    "    y_pred = model(x_data) # 计算y_head\n",
    "    loss = criterion(y_pred, y_data) # 计算Loss\n",
    "    print(epoch, loss.item()) # loss在打印时会自动调用__str__()\n",
    "\n",
    "    optimizer.zero_grad() # 梯度归零 \n",
    "\n",
    "    # 反馈\n",
    "    loss.backward() \n",
    "    # Update\n",
    "    optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "938dd2e2-e907-40bb-bc1a-fa6da7ed8360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w= 0.6934626698493958\n",
      "b= 1.8945298194885254\n",
      "y_pred= tensor([[4.6684]])\n"
     ]
    }
   ],
   "source": [
    "# Output weight and bias\n",
    "print('w=', model.linear.weight.item())\n",
    "print('b=', model.linear.bias.item())\n",
    "\n",
    "# Test Model\n",
    "x_test = torch.Tensor([[4.0]])\n",
    "y_test = model(x_test)\n",
    "print('y_pred=', y_test.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba13b059-2b03-4544-b702-5e639bd00735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced9246-cdd4-4609-a17a-6451ee45d61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
