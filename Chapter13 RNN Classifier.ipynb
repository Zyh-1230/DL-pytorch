{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8079f006-5549-4179-a748-dfa656d5d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gzip\n",
    "import csv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "85e1051d-2696-478b-bc23-716565a8a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 256\n",
    "N_LAYER = 2\n",
    "N_EPOCHS = 500\n",
    "N_CHARS = 128\n",
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0e831f9f-a8f1-4d3b-93be-5f8fd95a10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataset(Dataset):\n",
    "    def __init__(self, is_train_set=True):\n",
    "        filename = 'names_train.csv.gz' if is_train_set else 'names_test.csv.gz'\n",
    "        with gzip.open(filename, 'rt') as f:\n",
    "            reader = csv.reader(f)\n",
    "            rows = list(reader)\n",
    "        self.names = [row[0] for row in rows]\n",
    "        self.len = len(self.names)\n",
    "        self.countries = [row[1] for row in rows]\n",
    "        self.country_list = list(sorted(set(self.countries)))\n",
    "        self.country_dict = self.getCountryDict()\n",
    "        self.country_num = len(self.country_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.names[index], self.country_dict[self.countries[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def getCountryDict(self):\n",
    "        country_dict = dict()\n",
    "        for idx, country_name in enumerate(self.country_list, 0):\n",
    "            country_dict[country_name] = idx\n",
    "        return country_dict\n",
    "\n",
    "    def idx2country(self, index):\n",
    "        return self.country_list[index]\n",
    "    def getCountriesNum(self):\n",
    "        return self.country_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "643535be-0d7a-4dab-9196-93552579b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = NameDataset(is_train_set=True)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "testset = NameDataset(is_train_set=False)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "N_COUNTRY = trainset.getCountriesNum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5db954b2-63da-4452-9bcc-9e6dfb874cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, bidirectional=True):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_directions = 2 if bidirectional else 1\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size) # (seq_len, batchSize)----Embedding---->(seq_len, batchSize, hiddenSize)\n",
    "        # input:(seqlen, batchSize, hiddenSize) hidden:(nLayers*nDirections, batchSize, hiddenSize)---GRU--->output(seqlen, batchSize, hiddenSize*nDirections) hidden:(nLayers*nDirections, batchSize, hiddenSize)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * self.n_directions, output_size)\n",
    "\n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)\n",
    "        return create_tensor(hidden)\n",
    "\n",
    "    def forward(self, input, seq_lengths):\n",
    "        # input shape: B x S -> S x B\n",
    "        input = input.t()\n",
    "        batch_size = input.size(1) # save batch_size for make initial hidden(nLayer * nDirections, batchSize, hiddenSize)\n",
    "\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        embedding = self.embedding(input) # result of embedding with shape(seqlen, batchSize, hiddenSize)\n",
    "\n",
    "        gru_input = pack_padded_sequence(embedding, seq_lengths) # returns a PackedSequence object\n",
    "\n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "        if self.n_directions == 2:\n",
    "            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim=1) # if we use bidirectional GRU, the forward hidden and backward hidden should be concatenate\n",
    "        else:\n",
    "            hidden_cat = hidden[-1]\n",
    "        fc_output = self.fc(hidden_cat) # use linear classifier\n",
    "        return fc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0bbefed8-556d-49e3-bf21-2f5449e2a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def name2list(name):\n",
    "    arr = [ord(c) for c in name]\n",
    "    return arr, len(arr)\n",
    "\n",
    "def create_tensor(tensor):\n",
    "    if USE_GPU:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        tensor = tensor.to(device)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c7142f8e-5297-4535-9e4a-25b38b39470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensors(names, countries):\n",
    "    sequences_and_lengths = [name2list(name) for name in names]\n",
    "    name_sequences = [sl[0] for sl in sequences_and_lengths]\n",
    "    seq_lengths = torch.LongTensor([sl[1] for sl in sequences_and_lengths])\n",
    "    countries = countries.long()\n",
    "\n",
    "    # step: 填充0\n",
    "    seq_tensor = torch.zeros(len(name_sequences), seq_lengths.max()).long()\n",
    "    for idx, (seq, seq_len) in enumerate(zip(name_sequences, seq_lengths), 0):\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "\n",
    "    # sort by length to use pack_padded_sequence\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(dim=0, descending=True)\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "    countries = countries[perm_idx]\n",
    "\n",
    "    return create_tensor(seq_tensor), create_tensor(seq_lengths), create_tensor(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f34bb0b1-5903-4662-bb30-90d06a6c250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel():\n",
    "    total_loss = 0\n",
    "    for i, (names, countries) in enumerate(trainloader, 1):\n",
    "        inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "        output = classifier(inputs, seq_lengths)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print(f'[{time_since(start)}] Epoch {epoch}', end='')\n",
    "            print(f'[{i * len(inputs)}/{len(trainset)}]', end='')\n",
    "            print(f'loss={total_loss / (i * len(inputs))}')\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e4a4f694-82a1-4542-b2c2-758f855b3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel():\n",
    "    correct = 0\n",
    "    total = len(testset)\n",
    "    print(\"evaluating trained model...\")\n",
    "    with torch.no_grad():\n",
    "        for i, (names, countries) in enumerate(testloader, 1):\n",
    "            inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "            output = classifier(inputs, seq_lengths)\n",
    "            pred = output.max(dim=1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        percent = '%.2f' % (100 * correct / total)\n",
    "        print(f'Test set: Accuracy {correct} / {total} {percent}%')\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d2472c71-2964-4877-99e8-3a620b1987d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 500 epochs...\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 2559 / 6700 38.19%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3412 / 6700 50.93%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3520 / 6700 52.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3449 / 6700 51.48%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3370 / 6700 50.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3291 / 6700 49.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3232 / 6700 48.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3174 / 6700 47.37%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3170 / 6700 47.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3169 / 6700 47.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3191 / 6700 47.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3275 / 6700 48.88%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3379 / 6700 50.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3592 / 6700 53.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3772 / 6700 56.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3911 / 6700 58.37%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3963 / 6700 59.15%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3964 / 6700 59.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3968 / 6700 59.22%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3974 / 6700 59.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3989 / 6700 59.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3990 / 6700 59.55%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3983 / 6700 59.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3984 / 6700 59.46%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3960 / 6700 59.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3975 / 6700 59.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3986 / 6700 59.49%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4031 / 6700 60.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4071 / 6700 60.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4085 / 6700 60.97%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4107 / 6700 61.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4131 / 6700 61.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4180 / 6700 62.39%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4231 / 6700 63.15%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4266 / 6700 63.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4277 / 6700 63.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4293 / 6700 64.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4337 / 6700 64.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4346 / 6700 64.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4359 / 6700 65.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4347 / 6700 64.88%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4349 / 6700 64.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4346 / 6700 64.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4382 / 6700 65.40%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4416 / 6700 65.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4420 / 6700 65.97%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4453 / 6700 66.46%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4478 / 6700 66.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4494 / 6700 67.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4507 / 6700 67.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4520 / 6700 67.46%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4545 / 6700 67.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4532 / 6700 67.64%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4559 / 6700 68.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4578 / 6700 68.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4605 / 6700 68.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4581 / 6700 68.37%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4567 / 6700 68.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4545 / 6700 67.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4564 / 6700 68.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4562 / 6700 68.09%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4570 / 6700 68.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4613 / 6700 68.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4661 / 6700 69.57%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4681 / 6700 69.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4697 / 6700 70.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4709 / 6700 70.28%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4713 / 6700 70.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4692 / 6700 70.03%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4713 / 6700 70.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4726 / 6700 70.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4730 / 6700 70.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4750 / 6700 70.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4764 / 6700 71.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4742 / 6700 70.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4732 / 6700 70.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4744 / 6700 70.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4756 / 6700 70.99%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4773 / 6700 71.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4784 / 6700 71.40%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4798 / 6700 71.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4779 / 6700 71.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4789 / 6700 71.48%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4783 / 6700 71.39%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4802 / 6700 71.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4820 / 6700 71.94%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4834 / 6700 72.15%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4860 / 6700 72.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4871 / 6700 72.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4868 / 6700 72.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4867 / 6700 72.64%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4856 / 6700 72.48%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4857 / 6700 72.49%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4864 / 6700 72.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4885 / 6700 72.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4905 / 6700 73.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4908 / 6700 73.25%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4932 / 6700 73.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4943 / 6700 73.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4949 / 6700 73.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4940 / 6700 73.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4943 / 6700 73.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4958 / 6700 74.00%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4959 / 6700 74.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4962 / 6700 74.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4967 / 6700 74.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4962 / 6700 74.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4969 / 6700 74.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4979 / 6700 74.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4985 / 6700 74.40%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5012 / 6700 74.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5019 / 6700 74.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5022 / 6700 74.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5011 / 6700 74.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5009 / 6700 74.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5010 / 6700 74.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5027 / 6700 75.03%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5047 / 6700 75.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5041 / 6700 75.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5047 / 6700 75.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5033 / 6700 75.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5027 / 6700 75.03%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5027 / 6700 75.03%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5032 / 6700 75.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5064 / 6700 75.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5065 / 6700 75.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5071 / 6700 75.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5074 / 6700 75.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5092 / 6700 76.00%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5097 / 6700 76.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5089 / 6700 75.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5085 / 6700 75.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5092 / 6700 76.00%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5122 / 6700 76.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5132 / 6700 76.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5115 / 6700 76.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5113 / 6700 76.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5121 / 6700 76.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5153 / 6700 76.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5149 / 6700 76.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5107 / 6700 76.22%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5095 / 6700 76.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5079 / 6700 75.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5084 / 6700 75.88%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5121 / 6700 76.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5142 / 6700 76.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5162 / 6700 77.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5164 / 6700 77.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5165 / 6700 77.09%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5176 / 6700 77.25%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5178 / 6700 77.28%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5180 / 6700 77.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5203 / 6700 77.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5215 / 6700 77.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5220 / 6700 77.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5216 / 6700 77.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5222 / 6700 77.94%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5228 / 6700 78.03%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5252 / 6700 78.39%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5266 / 6700 78.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5265 / 6700 78.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5267 / 6700 78.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5267 / 6700 78.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5268 / 6700 78.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5270 / 6700 78.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5269 / 6700 78.64%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5275 / 6700 78.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5264 / 6700 78.57%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5256 / 6700 78.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5265 / 6700 78.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5271 / 6700 78.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5281 / 6700 78.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5286 / 6700 78.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5282 / 6700 78.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5280 / 6700 78.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5276 / 6700 78.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5271 / 6700 78.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5279 / 6700 78.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5287 / 6700 78.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5303 / 6700 79.15%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5297 / 6700 79.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5313 / 6700 79.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5319 / 6700 79.39%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5327 / 6700 79.51%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5329 / 6700 79.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5334 / 6700 79.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5336 / 6700 79.64%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5321 / 6700 79.42%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5316 / 6700 79.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5320 / 6700 79.40%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5325 / 6700 79.48%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5318 / 6700 79.37%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5333 / 6700 79.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5347 / 6700 79.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5355 / 6700 79.93%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5360 / 6700 80.00%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5373 / 6700 80.19%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5371 / 6700 80.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5379 / 6700 80.28%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5385 / 6700 80.37%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5372 / 6700 80.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5383 / 6700 80.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5377 / 6700 80.25%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5386 / 6700 80.39%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5395 / 6700 80.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5379 / 6700 80.28%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5363 / 6700 80.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5378 / 6700 80.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5391 / 6700 80.46%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5383 / 6700 80.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5373 / 6700 80.19%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5375 / 6700 80.22%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5375 / 6700 80.22%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5369 / 6700 80.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5378 / 6700 80.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5386 / 6700 80.39%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5391 / 6700 80.46%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5384 / 6700 80.36%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5384 / 6700 80.36%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5388 / 6700 80.42%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5396 / 6700 80.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5411 / 6700 80.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5398 / 6700 80.57%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5390 / 6700 80.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5395 / 6700 80.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5392 / 6700 80.48%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5382 / 6700 80.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5379 / 6700 80.28%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5399 / 6700 80.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5406 / 6700 80.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5424 / 6700 80.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5431 / 6700 81.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5423 / 6700 80.94%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5426 / 6700 80.99%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5434 / 6700 81.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5439 / 6700 81.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5420 / 6700 80.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5433 / 6700 81.09%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5437 / 6700 81.15%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5424 / 6700 80.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5428 / 6700 81.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5434 / 6700 81.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5433 / 6700 81.09%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5448 / 6700 81.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5450 / 6700 81.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5452 / 6700 81.37%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5459 / 6700 81.48%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5467 / 6700 81.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5456 / 6700 81.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5450 / 6700 81.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5448 / 6700 81.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5449 / 6700 81.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5452 / 6700 81.37%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5440 / 6700 81.19%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5441 / 6700 81.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5447 / 6700 81.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5441 / 6700 81.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5445 / 6700 81.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5449 / 6700 81.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5451 / 6700 81.36%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5464 / 6700 81.55%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5467 / 6700 81.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5473 / 6700 81.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5479 / 6700 81.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5477 / 6700 81.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5462 / 6700 81.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5469 / 6700 81.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5469 / 6700 81.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5473 / 6700 81.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5464 / 6700 81.55%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5462 / 6700 81.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5465 / 6700 81.57%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5458 / 6700 81.46%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5455 / 6700 81.42%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5450 / 6700 81.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5460 / 6700 81.49%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5469 / 6700 81.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5471 / 6700 81.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5478 / 6700 81.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5482 / 6700 81.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5473 / 6700 81.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5479 / 6700 81.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5467 / 6700 81.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5456 / 6700 81.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5453 / 6700 81.39%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5455 / 6700 81.42%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5469 / 6700 81.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5481 / 6700 81.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5487 / 6700 81.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5494 / 6700 82.00%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5481 / 6700 81.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5491 / 6700 81.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5497 / 6700 82.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5498 / 6700 82.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5494 / 6700 82.00%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5479 / 6700 81.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5483 / 6700 81.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5497 / 6700 82.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5513 / 6700 82.28%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5509 / 6700 82.22%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5501 / 6700 82.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5505 / 6700 82.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5511 / 6700 82.25%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5502 / 6700 82.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5489 / 6700 81.93%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5489 / 6700 81.93%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5485 / 6700 81.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5485 / 6700 81.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5487 / 6700 81.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5490 / 6700 81.94%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5482 / 6700 81.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5492 / 6700 81.97%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5496 / 6700 82.03%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5491 / 6700 81.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5471 / 6700 81.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5474 / 6700 81.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5497 / 6700 82.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5505 / 6700 82.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5498 / 6700 82.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5501 / 6700 82.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5508 / 6700 82.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5510 / 6700 82.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5512 / 6700 82.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5520 / 6700 82.39%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5530 / 6700 82.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5518 / 6700 82.36%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5510 / 6700 82.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5513 / 6700 82.28%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5521 / 6700 82.40%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5526 / 6700 82.48%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5515 / 6700 82.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5517 / 6700 82.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5512 / 6700 82.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5511 / 6700 82.25%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5517 / 6700 82.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5514 / 6700 82.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5514 / 6700 82.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5524 / 6700 82.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5523 / 6700 82.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5529 / 6700 82.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5539 / 6700 82.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5540 / 6700 82.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5526 / 6700 82.48%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5517 / 6700 82.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5524 / 6700 82.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5528 / 6700 82.51%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5531 / 6700 82.55%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5535 / 6700 82.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5551 / 6700 82.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5548 / 6700 82.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5546 / 6700 82.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5554 / 6700 82.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5554 / 6700 82.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5553 / 6700 82.88%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5549 / 6700 82.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5554 / 6700 82.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5551 / 6700 82.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5547 / 6700 82.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5544 / 6700 82.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5548 / 6700 82.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5546 / 6700 82.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5545 / 6700 82.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5550 / 6700 82.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5544 / 6700 82.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5541 / 6700 82.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5543 / 6700 82.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5542 / 6700 82.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5551 / 6700 82.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5537 / 6700 82.64%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5518 / 6700 82.36%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5524 / 6700 82.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5537 / 6700 82.64%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5538 / 6700 82.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5541 / 6700 82.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5513 / 6700 82.28%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5503 / 6700 82.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5504 / 6700 82.15%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5551 / 6700 82.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5552 / 6700 82.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5533 / 6700 82.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5523 / 6700 82.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5521 / 6700 82.40%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5537 / 6700 82.64%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5560 / 6700 82.99%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5564 / 6700 83.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5570 / 6700 83.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5569 / 6700 83.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5569 / 6700 83.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5570 / 6700 83.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5564 / 6700 83.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5561 / 6700 83.00%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5563 / 6700 83.03%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5559 / 6700 82.97%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5557 / 6700 82.94%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5550 / 6700 82.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5536 / 6700 82.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5545 / 6700 82.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5556 / 6700 82.93%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5557 / 6700 82.94%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5566 / 6700 83.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5552 / 6700 82.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5530 / 6700 82.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5533 / 6700 82.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5553 / 6700 82.88%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5547 / 6700 82.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5571 / 6700 83.15%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5557 / 6700 82.94%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5568 / 6700 83.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5581 / 6700 83.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5580 / 6700 83.28%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5597 / 6700 83.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5595 / 6700 83.51%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5593 / 6700 83.48%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5598 / 6700 83.55%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5601 / 6700 83.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5591 / 6700 83.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5581 / 6700 83.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5586 / 6700 83.37%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5591 / 6700 83.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5597 / 6700 83.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5597 / 6700 83.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5604 / 6700 83.64%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5601 / 6700 83.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5603 / 6700 83.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5592 / 6700 83.46%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5595 / 6700 83.51%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5603 / 6700 83.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5607 / 6700 83.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5605 / 6700 83.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5614 / 6700 83.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5601 / 6700 83.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5590 / 6700 83.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5589 / 6700 83.42%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5590 / 6700 83.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5582 / 6700 83.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5597 / 6700 83.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5610 / 6700 83.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5606 / 6700 83.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5607 / 6700 83.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5607 / 6700 83.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5603 / 6700 83.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5601 / 6700 83.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5601 / 6700 83.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5599 / 6700 83.57%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5594 / 6700 83.49%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5590 / 6700 83.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5580 / 6700 83.28%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5594 / 6700 83.49%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5610 / 6700 83.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5605 / 6700 83.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5599 / 6700 83.57%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5602 / 6700 83.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5606 / 6700 83.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5601 / 6700 83.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5607 / 6700 83.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5607 / 6700 83.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5619 / 6700 83.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5616 / 6700 83.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5632 / 6700 84.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5632 / 6700 84.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5620 / 6700 83.88%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5608 / 6700 83.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5607 / 6700 83.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5622 / 6700 83.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5612 / 6700 83.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5614 / 6700 83.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5610 / 6700 83.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5603 / 6700 83.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5612 / 6700 83.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5609 / 6700 83.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5604 / 6700 83.64%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5603 / 6700 83.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5605 / 6700 83.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5612 / 6700 83.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5614 / 6700 83.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5626 / 6700 83.97%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5622 / 6700 83.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5623 / 6700 83.93%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5621 / 6700 83.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5628 / 6700 84.00%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5636 / 6700 84.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5635 / 6700 84.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5614 / 6700 83.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5610 / 6700 83.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5606 / 6700 83.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5603 / 6700 83.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5612 / 6700 83.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5604 / 6700 83.64%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5607 / 6700 83.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5611 / 6700 83.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5614 / 6700 83.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5609 / 6700 83.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5602 / 6700 83.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5603 / 6700 83.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5612 / 6700 83.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5609 / 6700 83.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5612 / 6700 83.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5610 / 6700 83.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5613 / 6700 83.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5613 / 6700 83.78%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_COUNTRY, N_LAYER) # instantiate the classifier model\n",
    "    if USE_GPU: # whether use GPU for train model\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        classifier.to(device)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"Training for %d epochs...\" % N_EPOCHS)\n",
    "    acc_list = []\n",
    "    for epoch in range(1, N_EPOCHS + 1):\n",
    "        trainModel()\n",
    "        acc = testModel()\n",
    "        acc_list.append(acc) # recording the accuracy of testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bc405299-730d-4b2b-beff-6adee972a941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "epoch = np.arange(1, len(acc_list) + 1, 1)\n",
    "acc_list = np.array(acc_list)\n",
    "plt.plot(epoch, acc_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "477713cd-b3e1-4574-a3fe-77cde2ff57c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NameDataset at 0x1696b1ca0>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca728509-638b-498e-98be-27d6791b4af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
