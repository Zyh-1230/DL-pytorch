{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8079f006-5549-4179-a748-dfa656d5d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gzip\n",
    "import csv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "85e1051d-2696-478b-bc23-716565a8a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 256\n",
    "N_LAYER = 2\n",
    "N_EPOCHS = 500\n",
    "N_CHARS = 128\n",
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0e831f9f-a8f1-4d3b-93be-5f8fd95a10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataset(Dataset):\n",
    "    def __init__(self, is_train_set=True):\n",
    "        filename = 'names_train.csv.gz' if is_train_set else 'names_test.csv.gz'\n",
    "        with gzip.open(filename, 'rt') as f:\n",
    "            reader = csv.reader(f)\n",
    "            rows = list(reader)\n",
    "        self.names = [row[0] for row in rows]\n",
    "        self.len = len(self.names)\n",
    "        self.countries = [row[1] for row in rows]\n",
    "        self.country_list = list(sorted(set(self.countries)))\n",
    "        self.country_dict = self.getCountryDict()\n",
    "        self.country_num = len(self.country_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.names[index], self.country_dict[self.countries[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def getCountryDict(self):\n",
    "        country_dict = dict()\n",
    "        for idx, country_name in enumerate(self.country_list, 0):\n",
    "            country_dict[country_name] = idx\n",
    "        return country_dict\n",
    "\n",
    "    def idx2country(self, index):\n",
    "        return self.country_list[index]\n",
    "    def getCountriesNum(self):\n",
    "        return self.country_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "643535be-0d7a-4dab-9196-93552579b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = NameDataset(is_train_set=True)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "testset = NameDataset(is_train_set=False)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "N_COUNTRY = trainset.getCountriesNum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5db954b2-63da-4452-9bcc-9e6dfb874cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, bidirectional=True):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_directions = 2 if bidirectional else 1\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size) # (seq_len, batchSize)----Embedding---->(seq_len, batchSize, hiddenSize)\n",
    "        # input:(seqlen, batchSize, hiddenSize) hidden:(nLayers*nDirections, batchSize, hiddenSize)---GRU--->output(seqlen, batchSize, hiddenSize*nDirections) hidden:(nLayers*nDirections, batchSize, hiddenSize)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * self.n_directions, output_size)\n",
    "\n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)\n",
    "        return create_tensor(hidden)\n",
    "\n",
    "    def forward(self, input, seq_lengths):\n",
    "        # input shape: B x S -> S x B\n",
    "        input = input.t()\n",
    "        batch_size = input.size(1) # save batch_size for make initial hidden(nLayer * nDirections, batchSize, hiddenSize)\n",
    "\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        embedding = self.embedding(input) # result of embedding with shape(seqlen, batchSize, hiddenSize)\n",
    "\n",
    "        gru_input = pack_padded_sequence(embedding, seq_lengths) # returns a PackedSequence object\n",
    "\n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "        if self.n_directions == 2:\n",
    "            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim=1) # if we use bidirectional GRU, the forward hidden and backward hidden should be concatenate\n",
    "        else:\n",
    "            hidden_cat = hidden[-1]\n",
    "        fc_output = self.fc(hidden_cat) # use linear classifier\n",
    "        return fc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0bbefed8-556d-49e3-bf21-2f5449e2a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def name2list(name):\n",
    "    arr = [ord(c) for c in name]\n",
    "    return arr, len(arr)\n",
    "\n",
    "def create_tensor(tensor):\n",
    "    if USE_GPU:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        tensor = tensor.to(device)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c7142f8e-5297-4535-9e4a-25b38b39470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensors(names, countries):\n",
    "    sequences_and_lengths = [name2list(name) for name in names]\n",
    "    name_sequences = [sl[0] for sl in sequences_and_lengths]\n",
    "    seq_lengths = torch.LongTensor([sl[1] for sl in sequences_and_lengths])\n",
    "    countries = countries.long()\n",
    "\n",
    "    # step: 填充0\n",
    "    seq_tensor = torch.zeros(len(name_sequences), seq_lengths.max()).long()\n",
    "    for idx, (seq, seq_len) in enumerate(zip(name_sequences, seq_lengths), 0):\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "\n",
    "    # sort by length to use pack_padded_sequence\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(dim=0, descending=True)\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "    countries = countries[perm_idx]\n",
    "\n",
    "    return create_tensor(seq_tensor), create_tensor(seq_lengths), create_tensor(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f34bb0b1-5903-4662-bb30-90d06a6c250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel():\n",
    "    total_loss = 0\n",
    "    for i, (names, countries) in enumerate(trainloader, 1):\n",
    "        inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "        output = classifier(inputs, seq_lengths)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print(f'[{time_since(start)}] Epoch {epoch}', end='')\n",
    "            print(f'[{i * len(inputs)}/{len[trainset]}]', end='')\n",
    "            print(f'loss={total_loss / (i * len(inputs))}')\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e4a4f694-82a1-4542-b2c2-758f855b3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel():\n",
    "    correct = 0\n",
    "    total = len(testset)\n",
    "    print(\"evaluating trained model...\")\n",
    "    with torch.no_grad():\n",
    "        for i, (names, countries) in enumerate(testloader, 1):\n",
    "            inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "            output = classifier(inputs, seq_lengths)\n",
    "            pred = output.max(dim=1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        percent = '%.2f' % (100 * correct / total)\n",
    "        print(f'Test set: Accuracy {correct} / {total} {percent}%')\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d2472c71-2964-4877-99e8-3a620b1987d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 500 epochs...\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 2858 / 6700 42.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3289 / 6700 49.09%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3224 / 6700 48.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3179 / 6700 47.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3155 / 6700 47.09%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3144 / 6700 46.93%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3138 / 6700 46.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3138 / 6700 46.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3137 / 6700 46.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3140 / 6700 46.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3153 / 6700 47.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3215 / 6700 47.99%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3412 / 6700 50.93%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3677 / 6700 54.88%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3880 / 6700 57.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3941 / 6700 58.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3928 / 6700 58.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3963 / 6700 59.15%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3995 / 6700 59.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4011 / 6700 59.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3994 / 6700 59.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3950 / 6700 58.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3895 / 6700 58.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3862 / 6700 57.64%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3850 / 6700 57.46%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3866 / 6700 57.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3873 / 6700 57.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3925 / 6700 58.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 3979 / 6700 59.39%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4028 / 6700 60.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4078 / 6700 60.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4136 / 6700 61.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4157 / 6700 62.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4166 / 6700 62.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4171 / 6700 62.25%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4184 / 6700 62.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4189 / 6700 62.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4199 / 6700 62.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4191 / 6700 62.55%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4204 / 6700 62.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4257 / 6700 63.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4256 / 6700 63.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4289 / 6700 64.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4285 / 6700 63.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4308 / 6700 64.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4358 / 6700 65.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4406 / 6700 65.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4449 / 6700 66.40%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4481 / 6700 66.88%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4534 / 6700 67.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4531 / 6700 67.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4557 / 6700 68.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4574 / 6700 68.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4557 / 6700 68.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4563 / 6700 68.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4578 / 6700 68.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4596 / 6700 68.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4582 / 6700 68.39%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4605 / 6700 68.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4598 / 6700 68.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4606 / 6700 68.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4612 / 6700 68.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4622 / 6700 68.99%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4636 / 6700 69.19%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4647 / 6700 69.36%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4624 / 6700 69.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4625 / 6700 69.03%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4639 / 6700 69.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4632 / 6700 69.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4648 / 6700 69.37%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4661 / 6700 69.57%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4676 / 6700 69.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4683 / 6700 69.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4701 / 6700 70.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4717 / 6700 70.40%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4718 / 6700 70.42%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4736 / 6700 70.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4741 / 6700 70.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4752 / 6700 70.93%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4753 / 6700 70.94%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4762 / 6700 71.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4770 / 6700 71.19%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4793 / 6700 71.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4792 / 6700 71.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4805 / 6700 71.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4796 / 6700 71.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4806 / 6700 71.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4807 / 6700 71.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4829 / 6700 72.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4830 / 6700 72.09%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4824 / 6700 72.00%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4839 / 6700 72.22%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4842 / 6700 72.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4852 / 6700 72.42%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4867 / 6700 72.64%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4881 / 6700 72.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4877 / 6700 72.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4881 / 6700 72.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4875 / 6700 72.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4880 / 6700 72.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4903 / 6700 73.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4912 / 6700 73.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4898 / 6700 73.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4930 / 6700 73.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4979 / 6700 74.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4989 / 6700 74.46%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5002 / 6700 74.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5003 / 6700 74.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 4998 / 6700 74.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5013 / 6700 74.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5013 / 6700 74.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5013 / 6700 74.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5022 / 6700 74.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5034 / 6700 75.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5032 / 6700 75.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5047 / 6700 75.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5050 / 6700 75.37%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5068 / 6700 75.64%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5085 / 6700 75.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5075 / 6700 75.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5065 / 6700 75.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5054 / 6700 75.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5056 / 6700 75.46%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5064 / 6700 75.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5070 / 6700 75.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5074 / 6700 75.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5065 / 6700 75.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5045 / 6700 75.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5026 / 6700 75.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5052 / 6700 75.40%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5073 / 6700 75.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5102 / 6700 76.15%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5085 / 6700 75.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5084 / 6700 75.88%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5067 / 6700 75.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5107 / 6700 76.22%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5137 / 6700 76.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5183 / 6700 77.36%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5174 / 6700 77.22%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5157 / 6700 76.97%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5149 / 6700 76.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5133 / 6700 76.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5131 / 6700 76.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5150 / 6700 76.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5167 / 6700 77.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5173 / 6700 77.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5166 / 6700 77.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5167 / 6700 77.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5175 / 6700 77.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5152 / 6700 76.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5142 / 6700 76.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5155 / 6700 76.94%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5173 / 6700 77.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5194 / 6700 77.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5192 / 6700 77.49%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5200 / 6700 77.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5203 / 6700 77.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5200 / 6700 77.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5200 / 6700 77.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5212 / 6700 77.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5230 / 6700 78.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5217 / 6700 77.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5195 / 6700 77.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5203 / 6700 77.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5209 / 6700 77.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5238 / 6700 78.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5271 / 6700 78.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5249 / 6700 78.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5215 / 6700 77.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5214 / 6700 77.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5251 / 6700 78.37%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5256 / 6700 78.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5268 / 6700 78.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5264 / 6700 78.57%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5259 / 6700 78.49%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5261 / 6700 78.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5268 / 6700 78.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5263 / 6700 78.55%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5263 / 6700 78.55%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5268 / 6700 78.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5270 / 6700 78.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5274 / 6700 78.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5293 / 6700 79.00%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5288 / 6700 78.93%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5298 / 6700 79.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5308 / 6700 79.22%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5302 / 6700 79.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5293 / 6700 79.00%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5295 / 6700 79.03%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5303 / 6700 79.15%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5306 / 6700 79.19%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5283 / 6700 78.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5264 / 6700 78.57%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5261 / 6700 78.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5274 / 6700 78.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5301 / 6700 79.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5315 / 6700 79.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5329 / 6700 79.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5314 / 6700 79.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5322 / 6700 79.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5328 / 6700 79.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5330 / 6700 79.55%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5330 / 6700 79.55%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5330 / 6700 79.55%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5327 / 6700 79.51%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5333 / 6700 79.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5348 / 6700 79.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5351 / 6700 79.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5347 / 6700 79.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5345 / 6700 79.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5351 / 6700 79.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5372 / 6700 80.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5367 / 6700 80.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5362 / 6700 80.03%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5369 / 6700 80.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5372 / 6700 80.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5355 / 6700 79.93%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5357 / 6700 79.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5361 / 6700 80.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5349 / 6700 79.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5339 / 6700 79.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5354 / 6700 79.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5382 / 6700 80.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5361 / 6700 80.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5346 / 6700 79.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5339 / 6700 79.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5353 / 6700 79.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5381 / 6700 80.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5389 / 6700 80.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5395 / 6700 80.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5396 / 6700 80.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5407 / 6700 80.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5407 / 6700 80.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5406 / 6700 80.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5402 / 6700 80.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5384 / 6700 80.36%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5375 / 6700 80.22%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5383 / 6700 80.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5399 / 6700 80.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5406 / 6700 80.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5372 / 6700 80.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5371 / 6700 80.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5392 / 6700 80.48%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5413 / 6700 80.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5419 / 6700 80.88%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5413 / 6700 80.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5414 / 6700 80.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5395 / 6700 80.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5402 / 6700 80.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5416 / 6700 80.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5417 / 6700 80.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5416 / 6700 80.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5424 / 6700 80.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5435 / 6700 81.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5449 / 6700 81.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5453 / 6700 81.39%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5453 / 6700 81.39%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5444 / 6700 81.25%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5438 / 6700 81.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5436 / 6700 81.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5436 / 6700 81.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5418 / 6700 80.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5430 / 6700 81.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5436 / 6700 81.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5436 / 6700 81.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5433 / 6700 81.09%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5430 / 6700 81.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5425 / 6700 80.97%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5409 / 6700 80.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5417 / 6700 80.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5424 / 6700 80.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5430 / 6700 81.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5439 / 6700 81.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5434 / 6700 81.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5428 / 6700 81.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5428 / 6700 81.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5430 / 6700 81.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5439 / 6700 81.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5438 / 6700 81.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5446 / 6700 81.28%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5443 / 6700 81.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5450 / 6700 81.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5466 / 6700 81.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5475 / 6700 81.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5466 / 6700 81.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5471 / 6700 81.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5479 / 6700 81.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5481 / 6700 81.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5474 / 6700 81.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5479 / 6700 81.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5478 / 6700 81.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5480 / 6700 81.79%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5487 / 6700 81.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5486 / 6700 81.88%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5485 / 6700 81.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5483 / 6700 81.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5495 / 6700 82.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5491 / 6700 81.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5485 / 6700 81.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5479 / 6700 81.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5469 / 6700 81.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5471 / 6700 81.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5473 / 6700 81.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5466 / 6700 81.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5461 / 6700 81.51%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5482 / 6700 81.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5472 / 6700 81.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5477 / 6700 81.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5481 / 6700 81.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5498 / 6700 82.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5495 / 6700 82.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5502 / 6700 82.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5499 / 6700 82.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5483 / 6700 81.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5484 / 6700 81.85%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5514 / 6700 82.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5505 / 6700 82.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5514 / 6700 82.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5505 / 6700 82.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5497 / 6700 82.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5493 / 6700 81.99%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5490 / 6700 81.94%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5506 / 6700 82.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5505 / 6700 82.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5508 / 6700 82.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5508 / 6700 82.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5488 / 6700 81.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5493 / 6700 81.99%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5486 / 6700 81.88%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5508 / 6700 82.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5511 / 6700 82.25%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5510 / 6700 82.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5512 / 6700 82.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5522 / 6700 82.42%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5525 / 6700 82.46%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5517 / 6700 82.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5499 / 6700 82.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5499 / 6700 82.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5500 / 6700 82.09%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5498 / 6700 82.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5493 / 6700 81.99%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5490 / 6700 81.94%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5489 / 6700 81.93%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5512 / 6700 82.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5532 / 6700 82.57%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5544 / 6700 82.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5543 / 6700 82.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5539 / 6700 82.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5542 / 6700 82.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5548 / 6700 82.81%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5553 / 6700 82.88%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5550 / 6700 82.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5543 / 6700 82.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5535 / 6700 82.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5528 / 6700 82.51%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5534 / 6700 82.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5524 / 6700 82.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5523 / 6700 82.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5504 / 6700 82.15%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5497 / 6700 82.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5499 / 6700 82.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5499 / 6700 82.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5510 / 6700 82.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5510 / 6700 82.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5518 / 6700 82.36%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5526 / 6700 82.48%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5531 / 6700 82.55%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5510 / 6700 82.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5501 / 6700 82.10%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5491 / 6700 81.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5516 / 6700 82.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5539 / 6700 82.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5543 / 6700 82.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5539 / 6700 82.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5546 / 6700 82.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5544 / 6700 82.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5549 / 6700 82.82%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5542 / 6700 82.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5536 / 6700 82.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5539 / 6700 82.67%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5540 / 6700 82.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5542 / 6700 82.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5546 / 6700 82.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5541 / 6700 82.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5543 / 6700 82.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5540 / 6700 82.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5558 / 6700 82.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5554 / 6700 82.90%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5544 / 6700 82.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5545 / 6700 82.76%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5542 / 6700 82.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5541 / 6700 82.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5546 / 6700 82.78%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5555 / 6700 82.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5559 / 6700 82.97%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5562 / 6700 83.01%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5564 / 6700 83.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5566 / 6700 83.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5567 / 6700 83.09%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5565 / 6700 83.06%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5563 / 6700 83.03%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5564 / 6700 83.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5575 / 6700 83.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5576 / 6700 83.22%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5579 / 6700 83.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5573 / 6700 83.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5569 / 6700 83.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5566 / 6700 83.07%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5570 / 6700 83.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5579 / 6700 83.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5591 / 6700 83.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5590 / 6700 83.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5572 / 6700 83.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5582 / 6700 83.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5573 / 6700 83.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5564 / 6700 83.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5558 / 6700 82.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5560 / 6700 82.99%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5564 / 6700 83.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5570 / 6700 83.13%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5572 / 6700 83.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5583 / 6700 83.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5575 / 6700 83.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5564 / 6700 83.04%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5569 / 6700 83.12%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5575 / 6700 83.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5572 / 6700 83.16%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5561 / 6700 83.00%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5555 / 6700 82.91%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5550 / 6700 82.84%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5556 / 6700 82.93%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5552 / 6700 82.87%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5544 / 6700 82.75%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5533 / 6700 82.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5533 / 6700 82.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5529 / 6700 82.52%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5533 / 6700 82.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5533 / 6700 82.58%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5540 / 6700 82.69%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5541 / 6700 82.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5541 / 6700 82.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5534 / 6700 82.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5543 / 6700 82.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5543 / 6700 82.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5558 / 6700 82.96%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5563 / 6700 83.03%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5583 / 6700 83.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5580 / 6700 83.28%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5581 / 6700 83.30%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5584 / 6700 83.34%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5582 / 6700 83.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5582 / 6700 83.31%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5595 / 6700 83.51%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5593 / 6700 83.48%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5603 / 6700 83.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5595 / 6700 83.51%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5577 / 6700 83.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5575 / 6700 83.21%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5577 / 6700 83.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5574 / 6700 83.19%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5579 / 6700 83.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5589 / 6700 83.42%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5585 / 6700 83.36%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5577 / 6700 83.24%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5585 / 6700 83.36%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5589 / 6700 83.42%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5579 / 6700 83.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5579 / 6700 83.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5579 / 6700 83.27%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5573 / 6700 83.18%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5590 / 6700 83.43%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5597 / 6700 83.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5589 / 6700 83.42%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5580 / 6700 83.28%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5583 / 6700 83.33%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5587 / 6700 83.39%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5589 / 6700 83.42%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5589 / 6700 83.42%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5578 / 6700 83.25%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5578 / 6700 83.25%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5585 / 6700 83.36%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5595 / 6700 83.51%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5598 / 6700 83.55%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5609 / 6700 83.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5601 / 6700 83.60%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5608 / 6700 83.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5599 / 6700 83.57%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5591 / 6700 83.45%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5594 / 6700 83.49%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5597 / 6700 83.54%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5603 / 6700 83.63%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5609 / 6700 83.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5609 / 6700 83.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5610 / 6700 83.73%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5605 / 6700 83.66%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5595 / 6700 83.51%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5602 / 6700 83.61%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5608 / 6700 83.70%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5609 / 6700 83.72%\n",
      "evaluating trained model...\n",
      "Test set: Accuracy 5604 / 6700 83.64%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_COUNTRY, N_LAYER) # instantiate the classifier model\n",
    "    if USE_GPU: # whether use GPU for train model\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        classifier.to(device)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"Training for %d epochs...\" % N_EPOCHS)\n",
    "    acc_list = []\n",
    "    for epoch in range(1, N_EPOCHS + 1):\n",
    "        trainModel()\n",
    "        acc = testModel()\n",
    "        acc_list.append(acc) # recording the accuracy of testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bc405299-730d-4b2b-beff-6adee972a941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "epoch = np.arange(1, len(acc_list) + 1, 1)\n",
    "acc_list = np.array(acc_list)\n",
    "plt.plot(epoch, acc_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477713cd-b3e1-4574-a3fe-77cde2ff57c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
