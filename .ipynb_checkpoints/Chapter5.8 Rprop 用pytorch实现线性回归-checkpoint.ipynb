{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042960e3-a3bb-4258-b330-a745fc2d73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5764c0e2-ee86-4b06-8f11-1b939242a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.Tensor([[1.0], [2.0], [3.0]])\n",
    "y_data = torch.Tensor([[2.0], [4.0], [6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "735a5b8c-084c-41e9-9848-34e96e79edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造模型\n",
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None) 实现全连接层\n",
    "        # in_features: 输入特征的数量(输入张量的最后一维大小) out_features:输出特征的数量(输出张量的最后一维大小)\n",
    "        # bias:是否添加可学习的偏置项\n",
    "        self.linear = torch.nn.Linear(1, 1) # 输入维度为1 输出维度为1 \n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x) # 对象+() 代表可调用对象\n",
    "        return y_pred\n",
    "\n",
    "model = LinearModel() # model is callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e3f9ef2-daa2-4c61-b771-6186acec80a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# 构造损失函数及优化器\n",
    "# class torch.nn.MSELoss(size_average=True, reduce=True)\n",
    "# size_average是否求所有样本的损失均值 reduce是否为降维处理\n",
    "# criterion(y_head, y)\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "# class torch.optim.SGD(params, lr=<object object>, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "# SGD随机梯度下降\n",
    "# params权重--在model中没有定义相应的权重 只有linear这一个成员 model.parameters()会检查model中所有成员 将相应的权重加到最后的训练结果上\n",
    "# lr--learning rate\n",
    "optimizer = torch.optim.Rprop(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ec372fc-d0c2-435f-a64a-90471ca20d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20.3485107421875\n",
      "1 19.871030807495117\n",
      "2 19.305709838867188\n",
      "3 18.638351440429688\n",
      "4 17.8533935546875\n",
      "5 16.934309005737305\n",
      "6 15.864322662353516\n",
      "7 14.62774658203125\n",
      "8 13.212114334106445\n",
      "9 11.611652374267578\n",
      "10 9.832645416259766\n",
      "11 7.901665687561035\n",
      "12 5.87800407409668\n",
      "13 3.8722658157348633\n",
      "14 2.0740113258361816\n",
      "15 0.7925297021865845\n",
      "16 0.5168034434318542\n",
      "17 0.5168034434318542\n",
      "18 0.48256927728652954\n",
      "19 0.502824604511261\n",
      "20 0.40969318151474\n",
      "21 0.38323307037353516\n",
      "22 0.4246499240398407\n",
      "23 0.3924338221549988\n",
      "24 0.3434486985206604\n",
      "25 0.34354934096336365\n",
      "26 0.33929017186164856\n",
      "27 0.3153150677680969\n",
      "28 0.2894655168056488\n",
      "29 0.26370927691459656\n",
      "30 0.24038046598434448\n",
      "31 0.22329892218112946\n",
      "32 0.19409111142158508\n",
      "33 0.18689578771591187\n",
      "34 0.19302481412887573\n",
      "35 0.17867326736450195\n",
      "36 0.1652596890926361\n",
      "37 0.1562974750995636\n",
      "38 0.14516164362430573\n",
      "39 0.13473129272460938\n",
      "40 0.12643840909004211\n",
      "41 0.11298663914203644\n",
      "42 0.10756959766149521\n",
      "43 0.10684703290462494\n",
      "44 0.1013203039765358\n",
      "45 0.097709059715271\n",
      "46 0.09427964687347412\n",
      "47 0.08924335241317749\n",
      "48 0.08433478325605392\n",
      "49 0.08007879555225372\n",
      "50 0.07353654503822327\n",
      "51 0.06980255246162415\n",
      "52 0.06759807467460632\n",
      "53 0.06593788415193558\n",
      "54 0.06247257441282272\n",
      "55 0.05956517904996872\n",
      "56 0.057098694145679474\n",
      "57 0.05384206399321556\n",
      "58 0.050566498190164566\n",
      "59 0.04754648357629776\n",
      "60 0.04427420347929001\n",
      "61 0.04053519293665886\n",
      "62 0.036331962794065475\n",
      "63 0.03169610723853111\n",
      "64 0.026720944792032242\n",
      "65 0.021597396582365036\n",
      "66 0.01666795089840889\n",
      "67 0.013639306649565697\n",
      "68 0.011828453280031681\n",
      "69 0.009484371170401573\n",
      "70 0.007303157821297646\n",
      "71 0.005515424069017172\n",
      "72 0.004968565888702869\n",
      "73 0.003104269038885832\n",
      "74 0.004735508002340794\n",
      "75 0.004735508002340794\n",
      "76 0.003161064349114895\n",
      "77 0.003275037044659257\n",
      "78 0.003275037044659257\n",
      "79 0.0029448415152728558\n",
      "80 0.0028322353027760983\n",
      "81 0.002694167662411928\n",
      "82 0.002521632704883814\n",
      "83 0.0023298640735447407\n",
      "84 0.0021247747354209423\n",
      "85 0.0019152690656483173\n",
      "86 0.00171665009111166\n",
      "87 0.0015542922774329782\n",
      "88 0.0013872913550585508\n",
      "89 0.0012031884398311377\n",
      "90 0.0010059250053018332\n",
      "91 0.0008032844634726644\n",
      "92 0.000609158945735544\n",
      "93 0.0005086983437649906\n",
      "94 0.00042903199209831655\n",
      "95 0.0003372416540514678\n",
      "96 0.00025253280182369053\n",
      "97 0.0001960065565072\n",
      "98 0.00016452203271910548\n",
      "99 0.00012649790733121336\n"
     ]
    }
   ],
   "source": [
    "# Training Cycle\n",
    "for epoch in range(100):\n",
    "    # 前馈\n",
    "    y_pred = model(x_data) # 计算y_head\n",
    "    loss = criterion(y_pred, y_data) # 计算Loss\n",
    "    print(epoch, loss.item()) # loss在打印时会自动调用__str__()\n",
    "\n",
    "    optimizer.zero_grad() # 梯度归零 \n",
    "\n",
    "    # 反馈\n",
    "    loss.backward() \n",
    "    # Update\n",
    "    optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "938dd2e2-e907-40bb-bc1a-fa6da7ed8360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w= 1.9933407306671143\n",
      "b= 0.015697170048952103\n",
      "y_pred= tensor([[7.9891]])\n"
     ]
    }
   ],
   "source": [
    "# Output weight and bias\n",
    "print('w=', model.linear.weight.item())\n",
    "print('b=', model.linear.bias.item())\n",
    "\n",
    "# Test Model\n",
    "x_test = torch.Tensor([[4.0]])\n",
    "y_test = model(x_test)\n",
    "print('y_pred=', y_test.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba13b059-2b03-4544-b702-5e639bd00735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
