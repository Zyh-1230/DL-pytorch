{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "042960e3-a3bb-4258-b330-a745fc2d73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5764c0e2-ee86-4b06-8f11-1b939242a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.Tensor([[1.0], [2.0], [3.0]])\n",
    "y_data = torch.Tensor([[2.0], [4.0], [6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735a5b8c-084c-41e9-9848-34e96e79edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造模型\n",
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        # torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None) 实现全连接层\n",
    "        # in_features: 输入特征的数量(输入张量的最后一维大小) out_features:输出特征的数量(输出张量的最后一维大小)\n",
    "        # bias:是否添加可学习的偏置项\n",
    "        self.linear = torch.nn.Linear(1, 1) # 输入维度为1 输出维度为1 \n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x) # 对象+() 代表可调用对象\n",
    "        return y_pred\n",
    "\n",
    "model = LinearModel() # model is callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e3f9ef2-daa2-4c61-b771-6186acec80a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# 构造损失函数及优化器\n",
    "# class torch.nn.MSELoss(size_average=True, reduce=True)\n",
    "# size_average是否求所有样本的损失均值 reduce是否为降维处理\n",
    "# criterion(y_head, y)\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "# class torch.optim.SGD(params, lr=<object object>, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "# SGD随机梯度下降\n",
    "# params权重--在model中没有定义相应的权重 只有linear这一个成员 model.parameters()会检查model中所有成员 将相应的权重加到最后的训练结果上\n",
    "# lr--learning rate\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ec372fc-d0c2-435f-a64a-90471ca20d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.521478652954102\n",
      "1 6.706884860992432\n",
      "2 4.663931846618652\n",
      "3 3.233875274658203\n",
      "4 2.279752016067505\n",
      "5 1.6852445602416992\n",
      "6 1.3532991409301758\n",
      "7 1.2045661211013794\n",
      "8 1.1756927967071533\n",
      "9 1.2175239324569702\n",
      "10 1.293266773223877\n",
      "11 1.3766632080078125\n",
      "12 1.4502133131027222\n",
      "13 1.5034972429275513\n",
      "14 1.531615972518921\n",
      "15 1.5337947607040405\n",
      "16 1.5121467113494873\n",
      "17 1.4706239700317383\n",
      "18 1.414151668548584\n",
      "19 1.34794282913208\n",
      "20 1.276981234550476\n",
      "21 1.205664873123169\n",
      "22 1.1375812292099\n",
      "23 1.0754035711288452\n",
      "24 1.0208814144134521\n",
      "25 0.9748992919921875\n",
      "26 0.9375885725021362\n",
      "27 0.9084736108779907\n",
      "28 0.8866252303123474\n",
      "29 0.8708228468894958\n",
      "30 0.8596944212913513\n",
      "31 0.8518506288528442\n",
      "32 0.8459839820861816\n",
      "33 0.8409431576728821\n",
      "34 0.835787832736969\n",
      "35 0.8298115730285645\n",
      "36 0.8225417137145996\n",
      "37 0.8137308955192566\n",
      "38 0.8033251762390137\n",
      "39 0.7914297580718994\n",
      "40 0.7782673835754395\n",
      "41 0.7641394138336182\n",
      "42 0.749383270740509\n",
      "43 0.7343432903289795\n",
      "44 0.7193378210067749\n",
      "45 0.7046436071395874\n",
      "46 0.6904796361923218\n",
      "47 0.6770012378692627\n",
      "48 0.6643015146255493\n",
      "49 0.6524120569229126\n",
      "50 0.6413136124610901\n",
      "51 0.6309483647346497\n",
      "52 0.6212247610092163\n",
      "53 0.6120374202728271\n",
      "54 0.6032719612121582\n",
      "55 0.594817042350769\n",
      "56 0.5865707397460938\n",
      "57 0.5784467458724976\n",
      "58 0.5703760981559753\n",
      "59 0.5623111724853516\n",
      "60 0.5542210936546326\n",
      "61 0.5460968017578125\n",
      "62 0.5379402041435242\n",
      "63 0.5297657251358032\n",
      "64 0.5215972661972046\n",
      "65 0.5134619474411011\n",
      "66 0.5053890943527222\n",
      "67 0.4974062442779541\n",
      "68 0.48953741788864136\n",
      "69 0.48180297017097473\n",
      "70 0.47421762347221375\n",
      "71 0.4667889177799225\n",
      "72 0.4595206379890442\n",
      "73 0.45241063833236694\n",
      "74 0.4454536736011505\n",
      "75 0.4386407732963562\n",
      "76 0.43196165561676025\n",
      "77 0.4254056215286255\n",
      "78 0.4189602732658386\n",
      "79 0.4126158654689789\n",
      "80 0.40636369585990906\n",
      "81 0.40019503235816956\n",
      "82 0.3941051959991455\n",
      "83 0.3880905508995056\n",
      "84 0.3821479380130768\n",
      "85 0.3762771189212799\n",
      "86 0.37047815322875977\n",
      "87 0.36475202441215515\n",
      "88 0.3591005802154541\n",
      "89 0.35352617502212524\n",
      "90 0.3480292558670044\n",
      "91 0.34261152148246765\n",
      "92 0.33727434277534485\n",
      "93 0.3320176601409912\n",
      "94 0.32684117555618286\n",
      "95 0.32174527645111084\n",
      "96 0.316727876663208\n",
      "97 0.3117882013320923\n",
      "98 0.3069244623184204\n",
      "99 0.3021346926689148\n"
     ]
    }
   ],
   "source": [
    "# Training Cycle\n",
    "for epoch in range(100):\n",
    "    # 前馈\n",
    "    y_pred = model(x_data) # 计算y_head\n",
    "    loss = criterion(y_pred, y_data) # 计算Loss\n",
    "    print(epoch, loss.item()) # loss在打印时会自动调用__str__()\n",
    "\n",
    "    optimizer.zero_grad() # 梯度归零 \n",
    "\n",
    "    # 反馈\n",
    "    loss.backward() \n",
    "    # Update\n",
    "    optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "938dd2e2-e907-40bb-bc1a-fa6da7ed8360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w= 0.7134557366371155\n",
      "b= 1.1342132091522217\n",
      "y_pred= tensor([[3.9880]])\n"
     ]
    }
   ],
   "source": [
    "# Output weight and bias\n",
    "print('w=', model.linear.weight.item())\n",
    "print('b=', model.linear.bias.item())\n",
    "\n",
    "# Test Model\n",
    "x_test = torch.Tensor([[4.0]])\n",
    "y_test = model(x_test)\n",
    "print('y_pred=', y_test.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba13b059-2b03-4544-b702-5e639bd00735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
